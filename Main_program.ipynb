{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.config.list_physical_devices('GPU')\n",
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "#from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import  confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "#import pydot\n",
    "#import pydot_ng as pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot\n",
    "plot_model(model, to_file = \"Model.png\",  show_shapes=True,  rankdir='TB',expand_nested= True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/ec2-user/SageMaker/Train2\")\n",
    "#input_folder_path=os.getcwd()\n",
    "#all= input_folder_path.split('/')\n",
    "filename='combined_all_L_128_128.csv' #'combined_all_partial.csv'#filename='combined_all_1_L_32_32.csv'\n",
    "print(filename)\n",
    "#train_df = pd.read_csv(filename)\n",
    "train_df = pd.read_csv(filename)\n",
    "train_labels1 =  train_df['Label '].values #train_df['Label '].values\n",
    "#train_labels1 = train_df.iloc[0:,0].values\n",
    "#train_labels1 = to_categorical(train_labels1)\n",
    "print(train_labels1.shape)\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')/10000.0\n",
    "print(train_images.shape)\n",
    "train_images = train_images.reshape(72,128,128,3)\n",
    "print(train_images.shape)\n",
    "train_labels1 = train_labels1.reshape(72,128,1)\n",
    "train_labels4= np.zeros(72)\n",
    "for i in range(72):\n",
    "  #  for j in range(6):\n",
    "    if(train_labels1[i,0]  > 0):\n",
    "        train_labels4[i] = train_labels1[i,0]\n",
    "train_labels4=train_labels4.astype('int')\n",
    "print(train_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9486e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train111 = np. concatenate((train_images, train_images))\n",
    "labelsss = np. concatenate((train_labels4, train_labels4))\n",
    "#classes=['low','moderate','high','very high']\n",
    "classes=['no carbon','very low', 'low','moderate','high','very high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f120e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train111.shape, labelsss.shape)\n",
    "train_label=train_labels4.reshape(-1,)\n",
    "train_labels=labelsss.reshape(-1,)\n",
    "print(labelsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x,y,index):\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.imshow(x[index])\n",
    "    plt.xlabel(classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(train_images,train_label,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train,  x_test, y_train, y_test = train_test_split(train_images,train_label,random_state=2020,test_size=0.2)\n",
    "x_train,  x_test, y_train, y_test = train_test_split(train111,train_labels,random_state=2020,test_size=0.2)\n",
    "#x_train= train_images\n",
    "#y_train =train_label\n",
    "print(x_train.shape)\n",
    "#print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "#x_test=train_images\n",
    "#y_test = train_label\n",
    "#x_train= train_images\n",
    "#y_train =train_label\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=16,kernel_size=(3,3), strides=(2,2), input_shape=(32,32,3), data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "  #  keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "   # keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=16,kernel_size=(3,3), strides=(2,2), input_shape=(64,64,3), data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "  #  keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "   # keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "  #  keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=1024, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9bc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 16\n",
    "epochs=100\n",
    "#learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "#sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "#lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#es = EarlyStopping(monitor='accuracy', mode='max', min_delta=5)\n",
    "#cb = Callback(es)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "#cb_list = [cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a26bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "learn_rate=.001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist = model.fit(x_train,y_train, validation_data=(x_test, y_test),verbose=1, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)\n",
    "print(x_train.shape,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "#import efficientnet.tfkeras as efn\n",
    "print(x_train.shape,y_train1.shape)\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "base_model = EfficientNetB5(include_top=False, weights=\"imagenet\", input_shape=(128 , 128, 3 ),classes= y_train1)\n",
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=('relu'),input_dim=128))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(7,activation=('softmax')))\n",
    "\n",
    "#Adding the Dense layers along with activation and batch normalization\n",
    "model.summary()\n",
    "#Defining the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 8\n",
    "epochs=100\n",
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787119bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train1[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history=model.fit_generator(train_generator.flow(x_train,y_train1, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 2, callbacks = [es],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)\n",
    "print(x_train.shape,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96379671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "base_model = MobileNetV3Large(include_top=False, weights=None, input_shape=(128, 128, 3), alpha=1.0, classes=y_train1.shape[1])\n",
    "base_model.load_weights('weights_mobilenet_v3_large_224_1.0_float_no_top.h5') # give the path for downloaded weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import efficientnet.tfkeras as efn\n",
    "#print(x_train.shape,y_train1.shape)\n",
    "#from keras import backend as K\n",
    "#K.set_image_data_format('channels_last')\n",
    "#base_model = MobileNetV3Large(include_top=False, weights=\"imagenet\", input_shape=(64 , 64, 3 ),classes=y_train1.shape[1])\n",
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "model.add(Dense(512,activation=('relu')))\n",
    "model.add(Dense(256,activation=('relu')))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "model.add(Dense(64,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(7,activation=('softmax')))\n",
    "\n",
    "#Adding the Dense layers along with activation and batch normalization\n",
    "model.summary()\n",
    "#Defining the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 16\n",
    "epochs=100\n",
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be51196",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(train_generator.flow(x_train, y_train1, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 1, callbacks = [es],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)\n",
    "print(x_train.shape,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "#import efficientnet.tfkeras as efn\n",
    "print(x_train.shape,y_train1.shape)\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(64 , 64, 3 ),classes=y_train1.shape[1])\n",
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=('relu'),input_dim=256))\n",
    "model.add(Dense(256,activation=('relu')))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(7,activation=('softmax')))\n",
    "\n",
    "#Adding the Dense layers along with activation and batch normalization\n",
    "model.summary()\n",
    "#Defining the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5994753",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(train_generator.flow(x_train, y_train1, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 30, callbacks = [es],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7675926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=(3,3), strides=(2,2), input_shape=(128,128,3), data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59258dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist = model.fit(x_train,y_train,batch_size= 8,verbose=1,epochs=20)#,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Input, Cropping2D, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "#from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EFFICIENT NET (efnet)\n",
    "import keras.metrics\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=48,kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(256,256,3), data_format='channels_last'),\n",
    " #   keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    #keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "    #keras.layers.Conv2D(filters=64,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "  #  keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    #keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=192, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "    #keras.layers.Conv2D(filters=128,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "  #  keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=192, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "    #keras.layers.Conv2D(filters=256,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "  #  keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "   # keras.layers.Conv2D(filters=512,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "  #  keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "   # keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(2048, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2048, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "print(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996829ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',loss='categorical_crossentropy',  metrics=['accuracy'])#,keras.metrics.Precision(class_id=10), keras.metrics.Recall(class_id=10)])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy',keras.metrics.Precision(class_id=10), keras.metrics.Recall(class_id=10)])\n",
    "#model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(class_id=10), keras.metrics.Recall(class_id=10)])\n",
    "model.compile(optimizer=tf.optimizers.SGD(lr=0.001),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001))#, metrics=['accuracy',keras.metrics.Precision(class_id=10)])#, keras.metrics.Recall(class_id=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05214993",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist = model.fit(x_train,y_train,verbose=1,epochs=100)#,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "#import keras.utils\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "keras.utils.plot_model(model, to_file = \"Model.png\",  show_shapes=True,  rankdir='TB',expand_nested= True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78242fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbdb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = [np.argmax(element) for element in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classification Report:   \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066638f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debeb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08406629",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FlexibleNET (flxnet)\n",
    "import keras.metrics\n",
    "model = keras.models.Sequential([\n",
    "    #keras.layers.Conv2D(filters=32,kernel_size=(3,3), strides=(2,2), activation='relu', input_shape=(32,32,3), data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=32,kernel_size=(3,3), strides=(2,2), input_shape=(32,32,3), data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    #keras.layers.MaxPool2D((2,2)),\n",
    "    #keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    #keras.layers.Conv2D(filters=64,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    #keras.layers.MaxPool2D((2,2)),\n",
    "   # keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    #keras.layers.Conv2D(filters=128,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1),  padding=\"same\",data_format='channels_last'),\n",
    "    #keras.layers.Conv2D(filters=256,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\",data_format='channels_last'),\n",
    "   # keras.layers.Conv2D(filters=512,kernel_size=(3,3), activation='relu',padding='same'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\",data_format='channels_last'),\n",
    "    keras.layers.LeakyReLU(alpha=0.1),\n",
    "    keras.layers.BatchNormalization(),\n",
    "   # keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),data_format='channels_last'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024, activation='relu'),#kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0dca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['no carbon','very low','low','moderate','high','very high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/ec2-user/SageMaker/train1\")\n",
    "#input_folder_path=os.getcwd()\n",
    "#all= input_folder_path.split('/')\n",
    "filename='combined_all2.csv'\n",
    "print(filename)\n",
    "train_df = pd.read_csv(filename)\n",
    "train_labels1 = train_df['Labels'].values\n",
    "#train_labels1 = to_categorical(train_labels1)\n",
    "print(train_labels1.shape)\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')/10000.0\n",
    "train_images = train_images.reshape(944,32,32,3)\n",
    "print(train_images.shape)\n",
    "train_labels1 = train_labels1.reshape(944,32,1)\n",
    "train_labels4= np.zeros(944)\n",
    "for i in range(944):\n",
    "  #  for j in range(6):\n",
    "    if(train_labels1[i,0]  > 0):\n",
    "        train_labels4[i] = train_labels1[i,0]\n",
    "train_labels4=train_labels4.astype('int')\n",
    "print(train_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train_labels4.reshape(-1,)\n",
    "print(train_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,  x_test, y_train, y_test = train_test_split(train_images,train_label,random_state=2020,test_size=0.2)\n",
    "#x_train= train_images\n",
    "#y_train =train_label\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af492b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist = model.fit(x_train,y_train,verbose=1,epochs=25)#,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4822aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe622153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plot-keras-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c989108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "show_history(plot_hist)\n",
    "plot_history(plot_hist, path=\"standard.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0940132",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = [np.argmax(element) for element in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acc17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classification Report:   \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02f6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e47ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ac4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pydot\n",
    "!conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7204e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(model, to_file = \"Model.png\",  show_shapes=True,  rankdir='TB',expand_nested= True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vim custom-script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!conda install  pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!sudo apt-get install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo yum install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot\n",
    "pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pydot_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09330ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False, weights='imagenet',input_shape=(128,128,3))\n",
    "#model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad143ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_model(model, new_input_shape=(None, 40, 40, 3),custom_objects=None):\n",
    "    # replace input shape of first layer\n",
    "    \n",
    "    config = model.layers[0].get_config()\n",
    "    config['batch_input_shape']=new_input_shape\n",
    "    model._layers[0]=model.layers[0].from_config(config)\n",
    "\n",
    "    # rebuild model architecture by exporting and importing via json\n",
    "    new_model = tensorflow.keras.models.model_from_json(model.to_json(),custom_objects=custom_objects)\n",
    "\n",
    "    # copy weights from old model to new one\n",
    "    for layer in new_model._layers:\n",
    "        try:\n",
    "            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n",
    "            print(\"Loaded layer {}\".format(layer.name))\n",
    "        except:\n",
    "            print(\"Could not transfer weights for layer {}\".format(layer.name))\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = change_model(ResNet50,data_format='channels_last',new_input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import keras\n",
    "from keras.layers import Flatten, Dense\n",
    "#from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "#from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def abastufally():\n",
    "    weights = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_resnet_model = Sequential()\n",
    "\n",
    "pretrained_model_for_demo= tf.keras.applications.ResNet50(include_top=False,\n",
    "\n",
    "                   input_shape=(32,32,3),\n",
    "\n",
    "                   pooling='avg',classes=7,\n",
    "\n",
    "                   weights='imagenet')\n",
    "\n",
    "for each_layer in pretrained_model_for_demo.layers:\n",
    "\n",
    "        each_layer.trainable=False\n",
    "\n",
    "demo_resnet_model.add(pretrained_model_for_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_resnet_model.add(Flatten())\n",
    "\n",
    "demo_resnet_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "demo_resnet_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "demo_resnet_model.compile(optimizer=tf.optimizers.SGD(lr=0.001),loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee439a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = demo_resnet_model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd82101",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_resnet_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plot-keras-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "show_history(history)\n",
    "plot_history(history, path=\"standard_resnet50.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935047cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Flatten, Dense\n",
    "#from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "#from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def abastufally():\n",
    "    weights = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fa371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn\n",
    "#from tensorflow.keras.applications import EfficientNetB0\n",
    "base_model = efn.EfficientNetB0( include_top = False, weights = 'imagenet',input_tensor=Input(shape=(32, 32, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d990c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size = [224, 224,3]\n",
    "#new_train_x = x_train.resize((224,224,3))\n",
    "new_train_x = tf.image.resize(x_train, size=(224,224))\n",
    "new_train_x = tf.cast(new_train_x, dtype = tf.float32)\n",
    "print(new_train_x.shape)\n",
    "#ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "#from keras import backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "model = efn.EfficientNetB0(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,input_shape=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=tf.optimizers.SGD(lr=0.001),loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5573535",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.moveaxis(x_train , -1, 1)\n",
    "x.shape\n",
    "print( 'x', x,'x_train_______________',x_train,)\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#y_train = to_categorical(y_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b933a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn\n",
    "demo_eff_model = Sequential()\n",
    "\n",
    "model=efn.EfficientNetB0(include_top=False,\n",
    "\n",
    "                   pooling='avg',classes=7,\n",
    "\n",
    "                   weights='imagenet')\n",
    "\n",
    "for each_layer in model.layers:\n",
    "\n",
    "        each_layer.trainable=False\n",
    "\n",
    "demo_eff_model.add(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ec13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_eff_model.add(Flatten())\n",
    "\n",
    "demo_eff_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "demo_eff_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eae7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo_eff_model.compile(optimizer=tf.optimizers.SGD(lr=0.001),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#demo_eff_model.compile(optimizer=tf.optimizers.SGD(lr=0.001),loss='mean_squared_error', metrics=['accuracy'])\n",
    "demo_eff_model.compile(optimizer=tf.optimizers.SGD(lr=0.001),loss='cross_entropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.moveaxis(x_train, -1, 1)\n",
    "print(x.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdcfa89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = demo_eff_model.fit(x, y_train,  epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_efficientnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd242bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)\n",
    "print(x_train.shape,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "#import efficientnet.tfkeras as efn\n",
    "print(x_train.shape,y_train1.shape)\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "base_model = EfficientNetB5(include_top=False, weights=\"imagenet\", input_shape=(128 , 128, 3 ),classes=y_train1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten()) \n",
    "\n",
    "#Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the Dense layers along with activation and batch normalization\n",
    "model.add(Dense(512,activation=('relu'),input_dim=512))\n",
    "\n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "#model.add(Dropout(.3))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(7,activation=('softmax'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668eddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(x_train, y_train, epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 100, callbacks = [lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#es = EarlyStopping(monitor='accuracy', mode='max', min_delta=5)\n",
    "#cb = Callback(es)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)#, patience=20)\n",
    "#es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1)\n",
    "#cb_list = [cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "learn_rate=.001\n",
    "batch_size=32\n",
    "epochs=100\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01068e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_hist = model.fit(x_train,y_train1, validation_data=(x_test, y_test1),verbose=1, epochs=100, callbacks=[es])\n",
    "history1=model.fit_generator(train_generator.flow(x_train, y_train1, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 100,   verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameters\n",
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(train_generator.flow(x_train, y_train1, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 100, callbacks = [lrr],  verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plot-keras-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e20880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "show_history(history)\n",
    "plot_history(history, path=\"standard_efficient.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plotting the training and validation loss\n",
    "\n",
    "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
    "\n",
    "#Assigning the first subplot to graph training loss and validation loss\n",
    "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Plotting the training accuracy and validation accuracy\n",
    "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4387983",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca40191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)\n",
    "print(x_train,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import efficientnet.tfkeras as efn\n",
    "print(x_train.shape,y_train1.shape)\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(128 , 128, 3 ),classes=y_train1.shape[1])\n",
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten()) \n",
    "\n",
    "#Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the Dense layers along with activation and batch normalization\n",
    "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "\n",
    "model.add(Dense(512,activation=('relu'))) \n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "#model.add(Dropout(.3))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(7,activation=('softmax')))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dede18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameters\n",
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1=model.fit(x_train, y_train1, epochs = epochs, callbacks = [lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b06eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plot-keras-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plotting the training and validation loss\n",
    "#plt.subplot(1,2,2)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.tight_layout(pad=2.0)\n",
    "#f1.plot.xlabel('epochs')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax1.set_title('Loss')\n",
    "ax2.set_title('Accuracy')\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "#plt.grid(True)\n",
    "# Set the y axis label of the current axis.\n",
    "#plt.ylabel('Loss')\n",
    "#print(model.history.history['loss'])\n",
    "#print('I am here', model.history.history['loss'][-1])\n",
    "ax1.plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "#ax1.text('hello',loc='right top') {}\".format(input_var1)\n",
    "ax1.legend(['last value: {:.4f}'.format(model.history.history['loss'][-1])],loc='upper right')\n",
    "#annotate last value on the graph\n",
    "#ax1.annotate('%0.2f' % model.history.history['loss'][-1], xy=(1, model.history.history['loss'][-1]), xytext=(8, 0), \n",
    "          #   xycoords=('axes fraction', 'data'), textcoords='offset points')\n",
    "#ax2.savefig('resnet50_accuracy.png')\n",
    "ax2.plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax2.legend(['last value: {:.4f}'.format(model.history.history['accuracy'][-1])],loc='upper left')\n",
    "plt.savefig('mobilnetv3large_128_plots.png')\n",
    "#plt.text(.99, .99, 'matplotlib', ha='right', va='top', transform=ax.transAxes)\n",
    "#plt.subplot(2,2,2)\n",
    "#ax1=plt.subplot(2,2,2)\n",
    "#plt.xlabel('epochs')\n",
    "#plt.grid(True)\n",
    "# Set the y axis label of the current axis.\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.plot(model.history.history['accuracy'],color='b')\n",
    "#f,ax=plt.subplots(1,1) #Creates 2 subplots under 1 column\n",
    "#ax[0].plot.xlabel(\"epochs\")\n",
    "#Assigning the first subplot to graph training loss and validation loss\n",
    "#ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "#ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Plotting the training accuracy and validation accuracy\n",
    "#ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "#ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bd068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)\n",
    "print(x_train,y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38205b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV3Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,y_train1.shape)\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "base_model = MobileNetV3Large(include_top=False, weights=\"imagenet\", input_shape=(32 , 32, 3 ),classes=y_train1.shape[1])\n",
    "model1= Sequential()\n",
    "model1.add(base_model) \n",
    "model1.add(Flatten()) \n",
    "#Model summary\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3916cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "\n",
    "model1.add(Dense(512,activation=('relu'))) \n",
    "model1.add(Dense(256,activation=('relu'))) \n",
    "#model.add(Dropout(.3))\n",
    "model1.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model1.add(Dense(7,activation=('softmax')))\n",
    "\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42815d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "epochs=100\n",
    "learn_rate=.001\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "model1.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1=model1.fit_generator(train_generator.flow(x_train, y_train1, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = test_generator.flow(x_test, y_test1, batch_size = batch_size), validation_steps = 10, callbacks = [lrr],  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9681481",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plot-keras-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe822e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "show_history(history1)\n",
    "plot_history(history1, path=\"standard_mobilenetV3Large.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa8086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
